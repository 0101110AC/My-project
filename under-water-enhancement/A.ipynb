{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置环境变量解决OpenMP问题\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# 限制PyTorch线程数\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "project_path = Path(os.getcwd()).resolve()  # 获取当前工作目录\n",
    "print(f\"项目路径: {project_path}\")\n",
    "\n",
    "if str(project_path) not in sys.path:\n",
    "    sys.path.append(str(project_path))\n",
    "\n",
    "# 直接导入文件\n",
    "from generator import Generator\n",
    "from discriminator import Discriminator\n",
    "from dataset import UnderwaterDataset\n",
    "\n",
    "def verify_dataset(data_dir):\n",
    "    \"\"\"验证数据集结构和内容\"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    print(f\"\\n验证数据集:\")\n",
    "    print(f\"路径: {data_path}\")\n",
    "    print(f\"路径存在: {data_path.exists()}\")\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        print(\"错误: 数据集路径不存在\")\n",
    "        return False\n",
    "    \n",
    "    # 检查images目录\n",
    "    images_dir = data_path / 'images'\n",
    "    if not images_dir.exists():\n",
    "        print(\"错误: images目录不存在\")\n",
    "        return False\n",
    "    \n",
    "    # 获取所有图片\n",
    "    images = []\n",
    "    for ext in ['*.jpg', '*.JPG', '*.jpeg', '*.JPEG']:\n",
    "        images.extend(images_dir.glob(ext))\n",
    "    \n",
    "    total_images = len(images)\n",
    "    print(f\"\\n找到图片: {total_images} 张\")\n",
    "    \n",
    "    if images:\n",
    "        print(f\"示例: {images[0].name}\")\n",
    "        # 测试图片加载\n",
    "        try:\n",
    "            with Image.open(images[0]) as img:\n",
    "                print(f\"图片尺寸: {img.size}\")\n",
    "        except Exception as e:\n",
    "            print(f\"图片加载失败: {e}\")\n",
    "    \n",
    "    return total_images > 0\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # 基础配置\n",
    "        self.epochs = 10\n",
    "        self.batch_size = 8\n",
    "        self.lr = 0.0002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.image_size = 256\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # 路径配置\n",
    "        self.base_dir = Path(project_path)\n",
    "        self.data_dir = self.base_dir / \"train_data\"  # 数据集目录\n",
    "        self.checkpoint_dir = self.base_dir / \"checkpoints\"\n",
    "        self.results_dir = self.base_dir / \"results\"\n",
    "        \n",
    "        # 创建必要的目录\n",
    "        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def train():\n",
    "    # 创建配置\n",
    "    cfg = Config()\n",
    "    print(f\"使用设备: {cfg.device}\")\n",
    "    \n",
    "    # 验证数据集\n",
    "    if not verify_dataset(cfg.data_dir):\n",
    "        raise RuntimeError(\"数据集验证失败\")\n",
    "    \n",
    "    # 创建数据转换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((cfg.image_size, cfg.image_size)),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.1,  # 亮度调整\n",
    "            contrast=0.1,    # 对比度调整\n",
    "            saturation=0.1,  # 饱和度调整\n",
    "            hue=0.05        # 色调调整\n",
    "        ),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # 随机水平翻转\n",
    "        transforms.RandomVerticalFlip(p=0.5),    # 随机垂直翻转\n",
    "        transforms.RandomRotation(10),           # 随机旋转\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    # 创建数据集\n",
    "    print(\"\\n创建数据集...\")\n",
    "    try:\n",
    "        dataset = UnderwaterDataset(cfg.data_dir, transform=transform)\n",
    "        print(f\"数据集大小: {len(dataset)}\")\n",
    "        \n",
    "        # 测试第一张图片加载\n",
    "        if len(dataset) > 0:\n",
    "            print(\"\\n测试第一张图片加载:\")\n",
    "            first_image = dataset[0]\n",
    "            print(f\"图片尺寸: {first_image.shape}\")\n",
    "            print(f\"数值范围: [{first_image.min():.2f}, {first_image.max():.2f}]\")\n",
    "    except Exception as e:\n",
    "        print(f\"创建数据集失败: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    print(\"\\n创建数据加载器...\")\n",
    "    try:\n",
    "        dataloader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=cfg.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=0,  # 使用单进程\n",
    "            drop_last=True,\n",
    "            pin_memory=False  # 禁用pin_memory\n",
    "        )\n",
    "        print(f\"数据加载器创建成功，批次数: {len(dataloader)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"创建数据加载器失败: {e}\")\n",
    "        raise\n",
    "\n",
    "    # 初始化模型\n",
    "    generator = Generator().to(cfg.device)\n",
    "    discriminator = Discriminator().to(cfg.device)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    criterion_GAN = nn.BCELoss()\n",
    "    criterion_pixel = nn.L1Loss()\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=cfg.lr, betas=(cfg.b1, cfg.b2))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=cfg.lr, betas=(cfg.b1, cfg.b2))\n",
    "\n",
    "    # 训练循环\n",
    "    print(\"\\n开始训练...\")\n",
    "    latest_model_path = None  # 用于记录最新模型路径\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        # 使用单行进度条\n",
    "        progress_bar = tqdm(dataloader, \n",
    "                          desc=f\"Epoch {epoch}/{cfg.epochs}\",\n",
    "                          ncols=80,  # 设置进度条宽度\n",
    "                          leave=False)  # 完成后删除进度条\n",
    "        \n",
    "        # 记录每个epoch的平均损失\n",
    "        epoch_g_loss = 0\n",
    "        epoch_d_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for i, imgs in enumerate(progress_bar):\n",
    "            # 准备数据\n",
    "            real = torch.ones((imgs.size(0), 1, 16, 16), device=cfg.device)\n",
    "            fake = torch.zeros((imgs.size(0), 1, 16, 16), device=cfg.device)\n",
    "            real_imgs = imgs.to(cfg.device)\n",
    "            \n",
    "            # 训练生成器和判别器\n",
    "            optimizer_G.zero_grad()\n",
    "            gen_imgs = generator(real_imgs)\n",
    "            g_loss = criterion_GAN(discriminator(gen_imgs), real)\n",
    "            pixel_loss = criterion_pixel(gen_imgs, real_imgs)\n",
    "            g_total_loss = g_loss + 100 * pixel_loss\n",
    "            g_total_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            optimizer_D.zero_grad()\n",
    "            real_loss = criterion_GAN(discriminator(real_imgs), real)\n",
    "            fake_loss = criterion_GAN(discriminator(gen_imgs.detach()), fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # 更新损失统计\n",
    "            epoch_g_loss += g_total_loss.item()\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            # 更新进度条描述\n",
    "            progress_bar.set_postfix({\n",
    "                'G_loss': f'{g_total_loss.item():.2f}',\n",
    "                'D_loss': f'{d_loss.item():.2f}'\n",
    "            })\n",
    "        \n",
    "        # 打印每个epoch的平均损失\n",
    "        avg_g_loss = epoch_g_loss / batch_count\n",
    "        avg_d_loss = epoch_d_loss / batch_count\n",
    "        print(f\"Epoch {epoch}/{cfg.epochs} - \"\n",
    "              f\"Avg G_loss: {avg_g_loss:.4f}, \"\n",
    "              f\"Avg D_loss: {avg_d_loss:.4f}\")\n",
    "        \n",
    "        # 保存检查点和生成示例\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            # 保存模型并记录路径\n",
    "            generator_path = cfg.checkpoint_dir / f'generator_epoch_{epoch+1}.pth'\n",
    "            discriminator_path = cfg.checkpoint_dir / f'discriminator_epoch_{epoch+1}.pth'\n",
    "            \n",
    "            torch.save(generator.state_dict(), generator_path)\n",
    "            torch.save(discriminator.state_dict(), discriminator_path)\n",
    "            \n",
    "            latest_model_path = generator_path  # 记录最新的生成器模型路径\n",
    "            print(f\"\\n模型已保存: {latest_model_path}\")\n",
    "            \n",
    "            # 生成示例图像\n",
    "            with torch.no_grad():\n",
    "                sample_imgs = real_imgs[:4]\n",
    "                gen_imgs = generator(sample_imgs)\n",
    "                \n",
    "                # 转换为显示格式\n",
    "                gen_imgs = gen_imgs * 0.5 + 0.5\n",
    "                sample_imgs = sample_imgs * 0.5 + 0.5\n",
    "                \n",
    "                # 创建对比图\n",
    "                fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "                for j in range(4):\n",
    "                    axs[0, j].imshow(sample_imgs[j].cpu().permute(1, 2, 0))\n",
    "                    axs[0, j].axis('off')\n",
    "                    axs[0, j].set_title('Original')\n",
    "                    \n",
    "                    axs[1, j].imshow(gen_imgs[j].cpu().permute(1, 2, 0))\n",
    "                    axs[1, j].axis('off')\n",
    "                    axs[1, j].set_title('Enhanced')\n",
    "                \n",
    "                plt.savefig(cfg.results_dir / f'comparison_epoch_{epoch+1}.png')\n",
    "                plt.close()\n",
    "                \n",
    "    # 训练结束后打印最终模型路径\n",
    "    if latest_model_path:\n",
    "        print(f\"\\n最终模型保存在: {latest_model_path}\")\n",
    "\n",
    "# 验证环境\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA是否可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"当前GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# 开始训练\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        train()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n训练失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from generator import Generator\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import math\n",
    "import scipy.stats\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self):\n",
    "        # 配置\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.image_size = 256\n",
    "        \n",
    "        # 路径设置\n",
    "        self.base_dir = Path(project_path)\n",
    "        self.model_path = self.base_dir / \"checkpoints\" / \"generator_epoch_20.pth\"\n",
    "        self.test_dir = self.base_dir / \"test_data\" / \"images\"  # 测试图片目录\n",
    "        self.results_dir = self.base_dir / \"test_results\"\n",
    "        self.excel_path = self.base_dir / \"results\" / \"evaluation_results.xls\"\n",
    "        \n",
    "        # 验证路径\n",
    "        if not self.base_dir.exists():\n",
    "            raise RuntimeError(f\"基础目录不存在: {self.base_dir}\")\n",
    "        if not self.model_path.exists():\n",
    "            raise RuntimeError(f\"模型文件不存在: {self.model_path}\")\n",
    "        if not self.test_dir.exists():\n",
    "            raise RuntimeError(f\"测试目录不存在: {self.test_dir}\")\n",
    "            \n",
    "        # 创建结果目录\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.excel_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # 图像转换\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        \n",
    "        # 加载模型\n",
    "        print(f\"加载模型: {self.model_path}\")\n",
    "        self.generator = Generator().to(self.device)\n",
    "        self.generator.load_state_dict(torch.load(self.model_path))\n",
    "        self.generator.eval()\n",
    "    \n",
    "    def enhance_image(self, img_array):\n",
    "        \"\"\"增强图像处理\"\"\"\n",
    "        # 转换到LAB空间进行处理\n",
    "        lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        \n",
    "        # 自适应直方图均衡化\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        l = clahe.apply(l)\n",
    "        \n",
    "        # 合并通道\n",
    "        lab = cv2.merge((l,a,b))\n",
    "        enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        # 细节增强\n",
    "        enhanced = cv2.detailEnhance(enhanced, sigma_s=10, sigma_r=0.15)\n",
    "        \n",
    "        # 调整对比度和亮度\n",
    "        alpha = 1.1  # 对比度\n",
    "        beta = 5    # 亮度\n",
    "        enhanced = cv2.convertScaleAbs(enhanced, alpha=alpha, beta=beta)\n",
    "        \n",
    "        return enhanced\n",
    "        \n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"处理单张图片\"\"\"\n",
    "        # 加载并转换图片\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        original_size = img.size\n",
    "        \n",
    "        # 转换为tensor\n",
    "        input_tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # 生成增强图片\n",
    "        with torch.no_grad():\n",
    "            enhanced = self.generator(input_tensor)\n",
    "        \n",
    "        # 基础转换\n",
    "        enhanced = enhanced * 0.5 + 0.5\n",
    "        enhanced = enhanced.squeeze().cpu().permute(1, 2, 0).numpy()\n",
    "        enhanced = (enhanced * 255).clip(0, 255).astype('uint8')\n",
    "        \n",
    "        # 应用额外的图像增强\n",
    "        enhanced = self.enhance_image(enhanced)\n",
    "        \n",
    "        # 去噪处理\n",
    "        enhanced = cv2.fastNlMeansDenoisingColored(enhanced, None, 10, 10, 7, 21)\n",
    "        \n",
    "        # 转回PIL图像\n",
    "        enhanced_img = Image.fromarray(enhanced)\n",
    "        \n",
    "        # 调整回原始大小\n",
    "        if original_size != (self.image_size, self.image_size):\n",
    "            enhanced_img = enhanced_img.resize(original_size, Image.LANCZOS)\n",
    "        \n",
    "        return enhanced_img\n",
    "\n",
    "    def calculate_psnr(self, original, enhanced):\n",
    "        \"\"\"计算PSNR\"\"\"\n",
    "        return psnr(original, enhanced)\n",
    "    \n",
    "    def calculate_uciqe(self, img):\n",
    "        \"\"\"计算UCIQE\"\"\"\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        chroma = np.sqrt(np.square(a) + np.square(b))\n",
    "        \n",
    "        uc = np.mean(chroma)\n",
    "        sc = np.sqrt(np.mean(np.square(chroma - uc)))\n",
    "        cont = np.max(l) - np.min(l)\n",
    "        \n",
    "        uciqe = 0.4680 * sc + 0.2745 * cont + 0.2576 * uc\n",
    "        \n",
    "        return uciqe\n",
    "    \n",
    "    def calculate_uiqm(self, img):\n",
    "        \"\"\"计算UIQM\"\"\"\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        \n",
    "        uicm = np.mean(s)\n",
    "        uism = cv2.Laplacian(v, cv2.CV_64F).var()\n",
    "        uiconm = np.std(v)\n",
    "        \n",
    "        uiqm = 0.0282 * uicm + 0.2953 * uism + 0.6765 * uiconm\n",
    "        \n",
    "        return uiqm\n",
    "    \n",
    "    def test_all(self):\n",
    "        \"\"\"测试目录中的所有图片\"\"\"\n",
    "        print(f\"\\n开始测试...\")\n",
    "        test_images = sorted(list(self.test_dir.glob('*.jpg')))\n",
    "        results = []\n",
    "        \n",
    "        for img_path in test_images:\n",
    "            print(f\"处理图片: {img_path.name}\")\n",
    "            \n",
    "            # 处理图片\n",
    "            enhanced_img = self.process_image(img_path)\n",
    "            \n",
    "            # 计算指标\n",
    "            original = np.array(Image.open(img_path).convert('RGB'))\n",
    "            enhanced = np.array(enhanced_img)\n",
    "            \n",
    "            psnr_value = self.calculate_psnr(original, enhanced)\n",
    "            uciqe_value = self.calculate_uciqe(enhanced)\n",
    "            uiqm_value = self.calculate_uiqm(enhanced)\n",
    "            \n",
    "            results.append({\n",
    "                'image file name': img_path.name,\n",
    "                'PSNR': round(psnr_value, 4),\n",
    "                'UCIQE': round(uciqe_value, 4),\n",
    "                'UIQM': round(uiqm_value, 4)\n",
    "            })\n",
    "            \n",
    "            print(f\"PSNR: {round(psnr_value, 4)}\")\n",
    "            print(f\"UCIQE: {round(uciqe_value, 4)}\")\n",
    "            print(f\"UIQM: {round(uiqm_value, 4)}\\n\")\n",
    "            \n",
    "            # 保存对比图\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            \n",
    "            # 显示原图\n",
    "            original_img = Image.open(img_path).convert('RGB')\n",
    "            ax1.imshow(original_img)\n",
    "            ax1.set_title('Original')\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            # 显示增强图\n",
    "            ax2.imshow(enhanced_img)\n",
    "            ax2.set_title('Enhanced')\n",
    "            ax2.axis('off')\n",
    "            \n",
    "            # 保存对比图\n",
    "            plt.savefig(self.results_dir / f'comparison_{img_path.stem}.png', \n",
    "                       bbox_inches='tight', dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            # 单独保存增强图\n",
    "            enhanced_img.save(self.results_dir / f'enhanced_{img_path.stem}.png')\n",
    "        \n",
    "        # 创建DataFrame并保存结果\n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        try:\n",
    "            # 读取现有Excel文件的所有工作表\n",
    "            excel = pd.read_excel(self.excel_path, sheet_name=None)\n",
    "            \n",
    "            # 更新 attachment 2 results 工作表数据\n",
    "            excel['attachment 2 results'] = df\n",
    "            \n",
    "            # 保存所有工作表回Excel\n",
    "            with pd.ExcelWriter(self.excel_path, engine='openpyxl', mode='w') as writer:\n",
    "                for sheet_name, data in excel.items():\n",
    "                    data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            \n",
    "            print(f\"\\n数据已成功更新到 {self.excel_path} 的 attachment 2 results 工作表\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"更新Excel文件时出错: {str(e)}\")\n",
    "            # 保存为CSV备份\n",
    "            csv_path = self.results_dir / \"evaluation_results.csv\"\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"结果已保存到CSV文件: {csv_path}\")\n",
    "        \n",
    "        print(f\"\\n测试完成! 结果保存在: {self.results_dir}\")\n",
    "        print(\"\\n评估结果概要:\")\n",
    "        print(df.describe())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tester = Tester()\n",
    "    tester.test_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xhd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
